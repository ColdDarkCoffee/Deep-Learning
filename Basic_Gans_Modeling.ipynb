{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic_Gans_Modeling.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPTtvGrnZYSxJmCBmw8nnlN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ColdDarkCoffee/Deep-Learning/blob/main/Basic_Gans_Modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJmpRZ-xCIJX"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.core import Reshape, Dense, Dropout, Flatten\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Conv2D, UpSampling2D\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "from keras import initializers\n",
        "K.set_image_data_format('channels_first')"
      ],
      "metadata": {
        "id": "zulJgdjFLmwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# The dimensionality has been set at 100 for consistency with other GAN implementations. \n",
        "# But 10 works better here\n",
        "latent_dim = 100\n",
        "\n",
        "# Load MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
        "X_train = X_train[:, np.newaxis, :, :]\n",
        "\n",
        "# Use Adam as the Optimizer\n",
        "adam = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\n",
        "# Make our Generator Model\n",
        "generator = Sequential()\n",
        "\n",
        "# Transforms the input into a 7 × 7 128-channel feature map\n",
        "generator.add(Dense(128*7*7, input_dim=latent_dim))\n",
        "generator.add(LeakyReLU(0.2))\n",
        "generator.add(Reshape((128, 7, 7)))\n",
        "generator.add(UpSampling2D(size=(2, 2)))\n",
        "generator.add(Conv2D(64, kernel_size=(5, 5), padding='same'))\n",
        "generator.add(LeakyReLU(0.2))\n",
        "generator.add(UpSampling2D(size=(2, 2)))\n",
        "\n",
        "# Produces a 28 × 28 1-channel feature map (shape of a MNIST image)\n",
        "generator.add(Conv2D(1, kernel_size=(5, 5), padding='same', activation='tanh'))\n",
        "print(generator.summary())\n",
        "generator.compile(loss='binary_crossentropy', optimizer=adam)\n",
        "\n",
        "# Make our Discriminator Model\n",
        "discriminator = Sequential()\n",
        "discriminator.add(Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding='same', \n",
        "                         input_shape=(1, 28, 28), kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "discriminator.add(LeakyReLU(0.2))\n",
        "discriminator.add(Dropout(0.3))\n",
        "discriminator.add(Conv2D(128, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
        "discriminator.add(LeakyReLU(0.2))\n",
        "discriminator.add(Dropout(0.3))\n",
        "discriminator.add(Flatten())\n",
        "discriminator.add(Dense(1, activation='sigmoid'))\n",
        "print(discriminator.summary())\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=adam)\n",
        "\n",
        "# Creating the Adversarial Network. We need to make the Discriminator weights\n",
        "# non trainable. This only applies to the GAN model.\n",
        "discriminator.trainable = False\n",
        "ganInput = Input(shape=(latent_dim,))\n",
        "x = generator(ganInput)\n",
        "ganOutput = discriminator(x)\n",
        "gan = Model(inputs=ganInput, outputs=ganOutput)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=adam)\n",
        "\n",
        "# Our Discriminator and Generator Losses\n",
        "dLosses = []\n",
        "gLosses = []\n",
        "\n",
        "# Plot the loss from each batch\n",
        "def plotLoss(epoch):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.plot(dLosses, label='Discriminitive loss')\n",
        "    plt.plot(gLosses, label='Generative loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('images/dcgan_loss_epoch_%d.png' % epoch)\n",
        "\n",
        "# Create a wall of generated MNIST images\n",
        "def plotGeneratedImages(epoch, examples=100, dim=(10, 10), figsize=(10, 10)):\n",
        "    noise = np.random.normal(0, 1, size=[examples, latent_dim])\n",
        "    generatedImages = generator.predict(noise)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(generatedImages.shape[0]):\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "        plt.imshow(generatedImages[i, 0], interpolation='nearest', cmap='gray_r')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('images/dcgan_generated_image_epoch_%d.png' % epoch)\n",
        "\n",
        "# Save the generator and discriminator networks (and weights) for later use\n",
        "def saveModels(epoch):\n",
        "    generator.save('models/dcgan_generator_epoch_%d.h5' % epoch)\n",
        "    discriminator.save('models/dcgan_discriminator_epoch_%d.h5' % epoch)"
      ],
      "metadata": {
        "id": "XkUnKq4SLsAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpZuuHp6CSUx"
      },
      "source": [
        "epochs = 5\n",
        "batchSize = 128\n",
        "batchCount = X_train.shape[0] / batchSize\n",
        "\n",
        "print('Epochs:', epochs)\n",
        "print('Batch size:', batchSize)\n",
        "print('Batches per epoch:', batchCount)\n",
        "\n",
        "for e in range(1, epochs+1):\n",
        "    print('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "    for i in tqdm(range(int(batchCount))):\n",
        "        # Get a random set of input noise and images\n",
        "        noise = np.random.normal(0, 1, size=[batchSize, latent_dim])\n",
        "        imageBatch = X_train[np.random.randint(0, X_train.shape[0], size=batchSize)]\n",
        "\n",
        "        # Generate fake MNIST images\n",
        "        generatedImages = generator.predict(noise)\n",
        "        X = np.concatenate([imageBatch, generatedImages])\n",
        "\n",
        "        # Labels for generated and real data\n",
        "        yDis = np.zeros(2*batchSize)\n",
        "        # One-sided label smoothing\n",
        "        yDis[:batchSize] = 0.9\n",
        "\n",
        "        # Train discriminator\n",
        "        discriminator.trainable = True\n",
        "        dloss = discriminator.train_on_batch(X, yDis)\n",
        "\n",
        "        # Train generator\n",
        "        noise = np.random.normal(0, 1, size=[batchSize, latent_dim])\n",
        "        yGen = np.ones(batchSize)\n",
        "        discriminator.trainable = False\n",
        "        gloss = gan.train_on_batch(noise, yGen)\n",
        "\n",
        "    # Store loss of most recent batch from this epoch\n",
        "    dLosses.append(dloss)\n",
        "    gLosses.append(gloss)\n",
        "\n",
        "    if e == 1 or e % 5 == 0:\n",
        "        plotGeneratedImages(e)\n",
        "        \n",
        "        # Plot losses from every epoch\n",
        "        plotLoss(e)\n",
        "        saveModels(e)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}